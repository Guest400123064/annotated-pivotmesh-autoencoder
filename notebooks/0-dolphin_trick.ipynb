{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../dependencies/geometric-algebra-transformer\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from ezgatr.interfaces import point, rotation\n",
    "from gatr import GATr, SelfAttentionConfig, MLPConfig\n",
    "from tqdm import tqdm\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.transforms import random_rotation, matrix_to_quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(points, title=\"\"):\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter3D(x, y, z)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(190, 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dolphin mesh.\n",
    "device = \"cuda:0\"\n",
    "trg_obj = \"../data/tmp/dolphin.obj\"\n",
    "\n",
    "# We read the target 3D model using load_obj\n",
    "verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)\n",
    "\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "center = verts.mean(0)\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale\n",
    "\n",
    "# We construct a Meshes structure for the target mesh\n",
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])\n",
    "\n",
    "# We initialize the source shape to be a sphere of radius 1\n",
    "src_mesh = ico_sphere(4, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MVOnlyGATrModel(\n",
    "#     MVOnlyGATrConfig(\n",
    "#         num_layers=2,\n",
    "#         size_channels_in=2,\n",
    "#         size_channels_hidden=16,\n",
    "#         norm_channelwise_rescale=False,\n",
    "#         attn_is_causal=False,\n",
    "#     )\n",
    "# )\n",
    "model = GATr(\n",
    "    in_mv_channels=2,\n",
    "    out_mv_channels=1,\n",
    "    hidden_mv_channels=16,\n",
    "    in_s_channels=None,\n",
    "    out_s_channels=None,\n",
    "    hidden_s_channels=1,\n",
    "    num_blocks=2,\n",
    "    attention=SelfAttentionConfig(),  # Use default parameters for attention\n",
    "    mlp=MLPConfig(),  # Use default parameters for MLP\n",
    ")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "loop = tqdm(range(10001))\n",
    "for i in loop:\n",
    "    r = random_rotation(dtype=torch.float, device=device)\n",
    "    x = sample_points_from_meshes(trg_mesh, 1024)\n",
    "    y = torch.einsum(\"bni, ji -> bnj\", x.detach(), r)\n",
    "\n",
    "    x = point.encode(x).unsqueeze(-2)\n",
    "    r = (\n",
    "        rotation.encode(matrix_to_quaternion(r)[..., [1, 2, 3, 0]])\n",
    "        .reshape(1, 1, 1, 16)\n",
    "        .repeat((1, 1024, 1, 1))\n",
    "    )\n",
    "    p, _ = model(torch.cat([x, r], dim=-2), scalars=None)\n",
    "    # p = model(torch.cat([x, r], dim=-2))\n",
    "    p = point.decode(p).squeeze(-2)\n",
    "    loss = criterion(p, y)\n",
    "    losses.append(float(loss.detach().cpu()))\n",
    "\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    if i % 2000 == 0:\n",
    "        plot_pointcloud(p, title=\"iter: %d\" % i)\n",
    "        plot_pointcloud(y, title=\"iter: %d\" % i)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
